# llama3_RAG_test_v1
# LLaMA 3 RAG Chatbot

This repository contains a **Retrieval-Augmented Generation (RAG) chatbot** built with **LLaMA 3‚Äë8B** and **FAISS**, designed to answer questions from your personal documents (like PDFs). It uses **Ollama** for CPU-friendly LLaMA inference and **LangChain** for vector retrieval and embeddings.

---

## üöÄ Features

- Query personal PDFs or documents in natural language.
- FAISS-based semantic search for efficient retrieval.
- CPU-friendly setup (16 GB RAM, 12 logical CPU cores tested).
- Includes **thinking dots** to visualize when the model is processing.
- Handles all dependency issues and LangChain deprecations.
- Modular Python scripts:
  - `ingest.py` ‚Äî index your PDFs
  - `rag_chain.py` ‚Äî loads LLaMA + FAISS retriever
  - `chat.py` ‚Äî interactive chatbot

---

## üìÅ Repository Structure
basic_AI_chatbot/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îî‚îÄ‚îÄ documents/
‚îÇ ‚îî‚îÄ‚îÄ CV-Ali Shahid.pdf
‚îú‚îÄ‚îÄ vectorstore/
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ ingest.py
‚îÇ ‚îú‚îÄ‚îÄ rag_chain.py
‚îÇ ‚îî‚îÄ‚îÄ chat.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md


> **Note:** `vectorstore/` and PDFs are ignored in Git (`.gitignore`) for privacy and size.

---

## üõ† Setup Instructions

### 1Ô∏è‚É£ Clone the repository

```bash
git clone https://github.com/alishahidklair/llama3_RAG_test_v1.git
cd llama3_RAG_test_v1

### 2Ô∏è‚É£ Create a Python virtual environment

python3 -m venv AI_chatbot
source AI_chatbot/bin/activate

### 3Ô∏è‚É£ Install dependencies

pip install --upgrade pip
pip install -r requirements.txt

Dependencies: LangChain, LangChain Ollama & HuggingFace modules, FAISS CPU, PyPDF, Sentence Transformers, Ollama client, etc.

### 4Ô∏è‚É£ Install and run Ollama & pull LLaMA 3‚Äë8B



1. Install Ollama (see Ollama official docs: https://ollama.com/)

2. Pull the model:

ollama pull llama3


3. Start Ollama server:

ollama serve


The server must be running whenever you use the chatbot.


üìÑ Index Your Documents

Place your PDF documents in:

data/documents/


Then run:

python src/ingest.py


This creates a FAISS index in vectorstore/ for fast semantic search.

You only need to do this once unless you add new documents.

üí¨ Run the Chatbot
python src/chat.py


Ask questions interactively.

The model uses a thinking dots indicator so you know it‚Äôs processing.

Example:

Ask something (or 'exit'): What skills are mentioned in the CV?
...
Answer:
Python, JavaScript, SQL, Data Analysis


Type exit to quit.

CPU Note: On 16 GB RAM and 12 logical cores, replies may take 2‚Äì5 minutes per query. Consider smaller models for faster testing.

‚ö° Common Issues & Fixes

LangChain deprecation warnings

The class `Ollama` or `HuggingFaceEmbeddings` is deprecated.


Fixed by installing new packages:

pip install -U langchain-ollama langchain-huggingface


Import from updated modules:

from langchain_ollama import OllamaLLM
from langchain_huggingface import HuggingFaceEmbeddings


Module not found errors

Make sure you are in the virtual environment and installed dependencies:

source AI_chatbot/bin/activate
pip install -r requirements.txt


Git conflicts while pushing to GitHub

Resolve merge conflicts, then:

git add <file>
git rebase --continue
git push -u origin main


Or force push if the remote is empty:

git push -u origin main --force


FAISS / vectorstore issues

Make sure to run ingest.py before chat.py.

Never push vectorstore/ to GitHub (large files, private data).

‚öôÔ∏è Performance Tips

Set CPU threads in rag_chain.py:

import os
os.environ["OMP_NUM_THREADS"] = "12"


Use int8 quantization for LLaMA 3‚Äë8B (handled automatically by Ollama).

Keep the model loaded between queries to avoid long reload times.

üìå References

Ollama
 ‚Äî Model server and LLaMA 3‚Äë8B CPU inference

LangChain
 ‚Äî RAG pipelines

FAISS
 ‚Äî Vector search

Sentence Transformers
 ‚Äî Embeddings for semantic search

üìù License

This project is licensed under the MIT License ‚Äî see LICENSE for details.
You are free to use, modify, and distribute this code, with attribution.


---

If you want, I can also **write the matching `LICENSE` MIT file** with your name and year so it‚Äôs ready to push to GitHub.  

Do you want me to do that next?












